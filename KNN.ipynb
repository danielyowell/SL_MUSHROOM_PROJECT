{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORTS\n",
    "'''\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PREPROCESSING\n",
    "'''\n",
    "\n",
    "M = fetch_openml(data_id=24)\n",
    "x, y = M.data, M.target\n",
    "\n",
    "#! Convert the data to a pandas DataFrame\n",
    "M_features_df = pd.DataFrame(x, columns=M.feature_names)\n",
    "M_targets_df = pd.DataFrame(y, columns=['class'])\n",
    "\n",
    "M_everything_df = pd.concat([M_features_df, M_targets_df], axis=1)\n",
    "# print(M_everything_df.head())\n",
    "\n",
    "'''\n",
    "CONVERT TO NUMERICAL DATA\n",
    "'''\n",
    "mapping = {\n",
    "    'cap-shape': {'b': 0, 'c': 1, 'x': 2, 'f': 3, 'k': 4, 's': 5},\n",
    "    'cap-surface': {'f': 0, 'g': 1, 'y': 2, 's': 3},\n",
    "    'cap-color': {'n': 0, 'b': 1, 'c': 2, 'g': 3, 'r': 4, 'p': 5, 'u': 6, 'e': 7, 'w': 8, 'y': 9},\n",
    "    'bruises%3F': {'f': 0, 't': 1},\n",
    "    'odor': {'a': 0, 'l': 1, 'c': 2, 'y': 3, 'f': 4, 'm': 5, 'n': 6, 'p': 7, 's': 8},\n",
    "    'gill-attachment': {'a': 0, 'd': 1, 'f': 2, 'n': 3},\n",
    "    'gill-spacing': {'c': 0, 'w': 1, 'd': 2},\n",
    "    'gill-size': {'b': 0, 'n': 1},\n",
    "    'gill-color': {'k': 0, 'n': 1, 'b': 2, 'h': 3, 'g': 4, 'r': 5, 'o': 6, 'p': 7, 'u': 8, 'e': 9, 'w': 10, 'y': 11},\n",
    "    'stalk-shape': {'e': 0, 't': 1},\n",
    "    'stalk-root': {'b': 0, 'c': 1, 'u': 2, 'e': 3, 'z': 4, 'r': 5, '?': 6},\n",
    "    'stalk-surface-above-ring': {'f': 0, 'y': 1, 'k': 2, 's': 3},\n",
    "    'stalk-surface-below-ring': {'f': 0, 'y': 1, 'k': 2, 's': 3},\n",
    "    'stalk-color-above-ring': {'n': 0, 'b': 1, 'c': 2, 'g': 3, 'o': 4, 'p': 5, 'e': 6, 'w': 7, 'y': 8},\n",
    "    'stalk-color-below-ring': {'n': 0, 'b': 1, 'c': 2, 'g': 3, 'o': 4, 'p': 5, 'e': 6, 'w': 7, 'y': 8},\n",
    "    'veil-type': {'p': 0, 'u': 1},\n",
    "    'veil-color': {'n': 0, 'o': 1, 'w': 2, 'y': 3},\n",
    "    'ring-number': {'n': 0, 'o': 1, 't': 2},\n",
    "    'ring-type': {'c': 0, 'e': 1, 'f': 2, 'l': 3, 'n': 4, 'p': 5, 's': 6, 'z': 7},\n",
    "    'spore-print-color': {'k': 0, 'n': 1, 'b': 2, 'h': 3, 'r': 4, 'o': 5, 'u': 6, 'w': 7, 'y': 8},\n",
    "    'population': {'a': 0, 'c': 1, 'n': 2, 's': 3, 'v': 4, 'y': 5},\n",
    "    'habitat': {'g': 0, 'l': 1, 'm': 2, 'p': 3, 'u': 4, 'w': 5, 'd': 6},\n",
    "    'class': {'e': 0, 'p': 1}\n",
    "}\n",
    "for column, mp in mapping.items():\n",
    "    M_everything_df[column] = M_everything_df[column].replace(mp)\n",
    "# print(M_everything_df.head())\n",
    "\n",
    "le = LabelEncoder()\n",
    "M_everything_df_encoded = M_everything_df.apply(le.fit_transform)\n",
    "\n",
    "'''\n",
    "CLEAN DATA; VERIFY WITH STANDARD DEVIATION AND MEAN\n",
    "'''\n",
    "\n",
    "# veil-type has std = mean = 0 \n",
    "# remove veil-type column\n",
    "M_everything_df_encoded = M_everything_df_encoded.drop(columns='veil-type')\n",
    "\n",
    "# change to 1 to see std/mean outputs\n",
    "if(0):\n",
    "    print(\"standard deviations:\")\n",
    "    std = M_everything_df_encoded.std()\n",
    "    print(std)\n",
    "    print()\n",
    "    print(\"mean:\")\n",
    "    mean = M_everything_df_encoded.mean()\n",
    "    print(mean)\n",
    "\n",
    "'''\n",
    "SPLIT DATA\n",
    "'''\n",
    "# Now split and use the encoded DataFrame\n",
    "train, test = train_test_split(M_everything_df_encoded, test_size=.2, random_state=41)\n",
    "\n",
    "X_train = train.iloc[:,:-1].values\n",
    "Y_train = train.iloc[:,-1].values\n",
    "\n",
    "X_test = test.iloc[:,:-1].values\n",
    "Y_test = test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  3  1  6  1  0  0  7  1  0  3  3  3  7  2  1  4  1  5  6]\n",
      " [ 0  1  8  1  4  1  0  0 10  1  0  3  0  7  7  2  1  4  3  4  0]\n",
      " [ 0  1  8  1  4  1  0  0 10  1  0  0  0  7  7  2  1  4  3  3  4]\n",
      " [ 0  1  5  0  2  1  0  1  8  0  0  3  3  7  7  2  1  4  1  4  6]\n",
      " [ 0  1  7  0  8  1  0  1  2  1  4  3  3  5  7  2  1  0  7  4  3]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (21,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 47\u001b[0m\n\u001b[0;32m     41\u001b[0m new_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     42\u001b[0m                       [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     43\u001b[0m                       [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     44\u001b[0m                       [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]])\n\u001b[0;32m     46\u001b[0m new_points \u001b[38;5;241m=\u001b[39m normalize(new_points)\n\u001b[1;32m---> 47\u001b[0m knn \u001b[38;5;241m=\u001b[39m \u001b[43mfind_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_points\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m classifier(knn)\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mfind_neighbors\u001b[1;34m(k, X_tr, new_point)\u001b[0m\n\u001b[0;32m     28\u001b[0m neighbor_arr \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_tr)):\n\u001b[1;32m---> 30\u001b[0m     dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m(np\u001b[38;5;241m.\u001b[39msquare(\u001b[43mX_tr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnew_point\u001b[49m)))\n\u001b[0;32m     31\u001b[0m     neighbor_arr\u001b[38;5;241m.\u001b[39mappend([i, dist])\n\u001b[0;32m     32\u001b[0m neighbor_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(neighbor_arr, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (21,) (2,) "
     ]
    }
   ],
   "source": [
    "'''\n",
    "KNN FUNCTIONS \n",
    "'''\n",
    "\n",
    "# Feature scaling functions\n",
    "\n",
    "def normalize(X):\n",
    "    x1_min = min(X_train[:,0])\n",
    "    x1_max = max(X_train[:,0])\n",
    "    \n",
    "    f = lambda x: (x - x1_min)/(x1_max - x1_min)\n",
    "    X[:,0] = f(X[:,0])\n",
    "\n",
    "    x2_min = min(X_train[:,1])\n",
    "    x2_max = max(X_train[:,1])\n",
    "    \n",
    "    f = lambda x: (x - x2_min)/(x2_max - x2_min)\n",
    "    X[:,1] = f(X[:,1])\n",
    "    \n",
    "    return X\n",
    "\n",
    "X = normalize(X_train)\n",
    "\n",
    "print(X[0:5])\n",
    "\n",
    "# KNN\n",
    "def find_neighbors(k, X_tr, new_point):\n",
    "    neighbor_arr = []\n",
    "    for i in range(len(X_tr)):\n",
    "        dist = np.sqrt(sum(np.square(X_tr[i]-new_point)))\n",
    "        neighbor_arr.append([i, dist])\n",
    "    neighbor_arr = sorted(neighbor_arr, key = lambda x : x[1])\n",
    "    \n",
    "    return neighbor_arr[0:k]\n",
    "\n",
    "from collections import Counter\n",
    "def classifier(neighbor_arr):\n",
    "    class_arr = [Y_train[i[0]] for i in neighbor_arr]\n",
    "    return Counter(class_arr).most_common(1)[0][0]\n",
    "\n",
    "new_points = np.array([[-10, -10],\n",
    "                      [0, 10],\n",
    "                      [-15, 10],\n",
    "                      [5, -2]])\n",
    "\n",
    "new_points = normalize(new_points)\n",
    "knn = find_neighbors(4, X, new_points[1])\n",
    "classifier(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ANALYZE DATA\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
